name: Run PySpark Tests on Databricks (Manual)

on:
  workflow_dispatch:  # Only runs when manually triggered

jobs:
  run-tests:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Run tests on Databricks
      uses: databricks/run-notebook@v0
      with:
        databricks-host: ${{ secrets.DATABRICKS_HOST }}
        databricks-token: ${{ secrets.DATABRICKS_TOKEN }}
        local-notebook-path: test_runner.py
        new-cluster-json: |
          {
            "spark_version": "16.4.x-scala2.12",
            "node_type_id": "Standard_DS3_v2",
            "driver_node_type_id": "Standard_DS3_v2",
            "num_workers": 0,
            "autotermination_minutes": 20,
            "spark_conf": {
              "spark.databricks.cluster.profile": "singleNode",
              "spark.master": "local[*]"
            }
          }
        workspace-temp-dir: /tmp/databricks-github-actions
        git-provider: gitHub

