name: Run PySpark Tests on Databricks (Manual)

on:
  workflow_dispatch:  # Only runs when manually triggered

jobs:
  run-tests:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Run tests on Databricks
      uses: databricks/run-notebook@v0
      with:
        databricks-host: ${{ secrets.DATABRICKS_HOST }}
        databricks-token: ${{ secrets.DATABRICKS_TOKEN }}
        local-notebook-path: test_runner.py
        new-cluster-json: |
          {
            "spark_version": "16.4.x-scala2.12",
            "kind": "CLASSIC_PREVIEW",
            "is_single_node": true,
            "num_workers": 0,
            "node_type_id": "Standard_DS3_v2",
            "driver_node_type_id": "Standard_DS3_v2"
          }
        libraries-json: |
            [
              { "pypi": { "package": "pytest" } }
            ]
        workspace-temp-dir: /tmp/databricks-github-actions
        git-provider: gitHub

